---

---

# 数据治理那些事

> 最近比较忙，没咋记录，今天忙里偷闲，正好记录一下最近正在做的数据治理相关的工作。

## 💡 什么是数据治理（Data Governance）？

数据治理就是对企业内数据进行统一的管理和控制，确保数据在整个生命周期中是高质量、可控、可追溯、合规可用的。

一句话总结：
👉 数据治理 = 管好“数据”这件事的规则 + 流程 + 角色分工

## 🔍 为什么要做数据治理？

在笔者所接触的这个项目的数据问题包括如下：

- 同一指标、多个定义（口径混乱）；

- 多套数据系统，各自为政（信息孤岛）；

- 数据质量差（重复、缺失、错误）；

- 无法快速获得可信的数据支撑业务分析。

因此，数据治理的目标是解决这些问题，让数据成为一种有价值、可信赖的资产。

## 🧱 数据治理的核心内容（五大支柱）

- 数据标准：统一数据的命名、格式、口径、分类，比如“客户ID”的定义要一致。
- 数据质量：检测和修复数据中的缺失值、错误值、重复值、逻辑异常等问题。
- 主数据管理：（MDM）核心实体（如客户、产品、组织）要有唯一标准的主数据源。
- 元数据管理：描述数据的数据，包括数据的来源、变更路径、使用情况等。
- 权限与安全：谁可以访问哪些数据？是否符合数据安全合规要求？

## 👥 谁在做数据治理？（角色分工）

- 数据治理委员会：制定治理政策和战略，一般由高层领导组成。
- 数据架构师 / 数据治理专员：设计治理方案、制定标准、推动执行。
- 业务部门数据管理员（数据Owner）：负责各自业务线的数据定义、质量。
- IT / 数据平台团队：负责落地工具、建模、自动化检测等技术实现。

## 🛠️ 数据治理怎么落地？（实际做法）

构建可落地的数据治理平台，需从顶层设计出发，贯通战略目标、流程机制与平台工具。推荐采用“三层平台 + 两类门户”的体系化架构：

+-----------------------------+
|         数据门户层          | ← 面向用户：提供数据服务与治理工作台
+-----------------------------+
|     治理中台（规则+流程）   | ← 统一规则引擎、审批流、任务调度
+-----------------------------+
|     能力组件层（工具层）    | ← 具体实现元数据、主数据、质量、安全等功能
+-----------------------------+

- 数据服务门户：供业务人员查询、下载、订阅数据，形成数据服务闭环。

- 数据治理门户：供数据治理人员进行标准维护、质量监控、流程审批等。



### 核心模块

| 模块             | 功能目标                             | 示例内容                                   |
|------------------|--------------------------------------|--------------------------------------------|
| 元数据管理       | 管理数据从哪来，到哪去（数据上下文） | 表结构、字段定义、血缘关系、变更历史等     |
| 数据标准管理     | 建立统一的字段命名与指标口径         | 命名规范、编码标准、统一指标定义等         |
| 数据质量管理     | 自动发现和修复数据问题               | 校验规则、缺失检测、质量评分、数据审计     |
| 数据权限与安全   | 控制访问边界与保护敏感信息           | 数据分级分类、脱敏策略、权限审计等         |
| 数据目录与服务化 | 构建统一的数据资产入口               | 数据目录、标签体系、API 数据服务、工单流转 |

1. 元数据管理
职责：

采集技术元数据（表、字段、数据类型）

采集业务元数据（标签、定义、归属）

构建血缘关系图谱

关键构建点：

建立多源采集器（Hive, MySQL, Kafka, Airflow 等）

标准化元数据 Schema（表级、字段级、任务级）

构建数据血缘图（作业依赖解析 + SQL 解析）

推荐工具：

🧰 DataHub: 支持多种源的元数据采集、版本管理与血缘图谱。

🧰 Amundsen: 轻量化数据目录，适合嵌入 BI 门户。

🧰 OpenMetadata: 支持标签体系与治理流程协同。

2. 数据质量管理
职责：

定义数据质量规则（完整性、唯一性、准确性等）

自动执行质量检查

记录质量事件并告警

关键构建点：

规则定义 DSL + UI 支持（支持 SQL 和模板）

定时调度执行（结合 Airflow / Dagster）

异常记录、结果评分、质量趋势统计

推荐工具：

🧰 Great Expectations: 支持多种规则验证与数据文档生成。

🧰 Soda: 更轻量级的质量校验工具，适合自动 CI/CD 流程接入。

🧰 OpenDQ: 针对大型治理场景的企业级方案。

3. 数据标准管理
职责：

定义标准字段、标准指标、命名规范等

审批与发布标准

关联实际资产与标准的匹配程度

关键构建点：

标准存储模型（可版本化）

标准与资产自动比对算法（基于字段名/值域）

标准指标图谱构建

推荐工具：

🧰 OpenMetadata: 支持标准定义与指标目录管理。

🧰 Apache Atlas + 自研标准模块。

4. 权限与数据安全治理
职责：

数据分级分类

数据访问审计

动态脱敏与授权控制

关键构建点：

支持资源粒度的 RBAC（表/字段级）

元数据中集成安全等级字段

脱敏策略管理与审计日志回溯

推荐工具：

🧰 Apache Ranger: 与 Hive、Kafka、HBase 等组件无缝集成。

🧰 Ory: 高性能身份与权限管理框架。

🧰 自研脱敏组件（结合中间层 Proxy 或数据服务层）

## 推荐落地路线（实践建议）

| 阶段 | 建议动作 |
|------|----------|
| 初期 | 落地元数据管理、指标统一、数据目录构建 |
| 中期 | 引入数据质量平台、指标稽核、权限管理 |
| 后期 | 建设治理中台，接入全链路血缘、自动检测、治理工单系统 |

同时，应设立跨部门的数据治理小组，推动治理制度的落地与执行闭环。

📌 **扩展阅读推荐**：
- [DataHub 官方文档](https://datahubproject.io/docs/)
- [Great Expectations 实践案例](https://docs.greatexpectations.io/)
- [OpenLineage 在数据血缘中的角色](https://openlineage.io/)